# Advanced Agent Patterns - Complete Guide

## Overview

This guide explains `3.advanced_agent_patterns.py` - advanced patterns for building production-ready AI agents with LangChain.

**What you'll learn:** Dynamic model selection, dynamic prompt generation, complex structured output, and production best practices.

## Quick Start

```bash
# Run the example
python examples/3.advanced_agent_patterns.py
```

**Prerequisites:**
- Complete `2.simple_agent_basics.py` first
- Python 3.11+
- AI Toolkit installed: `pip install -e .`
- API keys configured in `.env`

---

## 1. Dynamic Model Selection

Automatically select the best model based on task complexity and requirements.

### Concept

Different tasks require different models:
- **Simple tasks** â†’ Fast, cheap models (e.g., deepseek-chat)
- **Complex tasks** â†’ Powerful models (e.g., gpt-4)
- **Code tasks** â†’ Specialized models (e.g., deepseek-coder)

### Implementation

```python
def select_model_for_task(task_description: str, model_manager: ModelManager):
    """
    Dynamically select the best model based on task complexity.
    
    Args:
        task_description: Description of the task
        model_manager: ModelManager instance
    
    Returns:
        Configured model for the task
    """
    task_lower = task_description.lower()
    
    # Complex reasoning tasks
    if any(keyword in task_lower for keyword in ['analyze', 'complex', 'detailed', 'research']):
        print("ðŸ“Š Selected: GLM-4.6 (complex reasoning)")
        return model_manager.create_model(
            provider_name="glm",
            model_name="glm-4.6",
            temperature=0.7,
            max_tokens=4000
        )
    
    # Code-related tasks
    elif any(keyword in task_lower for keyword in ['code', 'program', 'debug', 'function']):
        print("ðŸ’» Selected: DeepSeek-Coder (code tasks)")
        return model_manager.create_model(
            provider_name="deepseek",
            model_name="deepseek-coder",
            temperature=0.3,
            max_tokens=2000
        )
    
    # Simple tasks
    else:
        print("âš¡ Selected: DeepSeek-Chat (general tasks)")
        return model_manager.create_model(
            provider_name="deepseek",
            model_name="deepseek-chat",
            temperature=0.7,
            max_tokens=2000
        )
```

### Usage Example

```python
# Task 1: Simple question
model1 = select_model_for_task("What is 2 + 2?", model_manager)
# â†’ DeepSeek-Chat (fast, cheap)

# Task 2: Complex analysis
model2 = select_model_for_task("Analyze the economic impact of AI", model_manager)
# â†’ GLM-4.6 (powerful reasoning)

# Task 3: Code generation
model3 = select_model_for_task("Write a Python function to sort a list", model_manager)
# â†’ DeepSeek-Coder (specialized for code)
```

### Benefits

- âœ… **Cost optimization** - Use cheaper models for simple tasks
- âœ… **Performance optimization** - Use powerful models only when needed
- âœ… **Automatic selection** - No manual model switching
- âœ… **Scalability** - Easy to add new models and rules

### Production Considerations

```python
# Add cost tracking
def select_model_with_cost_tracking(task: str, budget: float):
    if budget < 0.01:
        return cheap_model  # Use cheapest model
    elif task_complexity > 0.8:
        return powerful_model  # Use best model
    else:
        return balanced_model  # Use mid-tier model

# Add performance monitoring
def select_model_with_monitoring(task: str):
    start_time = time.time()
    model = select_model_for_task(task, model_manager)
    selection_time = time.time() - start_time
    log_metric("model_selection_time", selection_time)
    return model
```

**Official Docs:** https://docs.langchain.com/oss/python/langchain/models

---

## 2. Dynamic Prompt Generation

Generate context-aware prompts based on task requirements.

### Concept

Different tasks need different prompts:
- **Analysis tasks** â†’ Detailed, structured prompts
- **Creative tasks** â†’ Open-ended, exploratory prompts
- **Technical tasks** â†’ Precise, specific prompts

### Implementation

```python
def generate_dynamic_prompt(task_type: str, context: dict) -> str:
    """
    Generate context-aware system prompts based on task type.
    
    Args:
        task_type: Type of task (analysis, creative, technical, support)
        context: Additional context (user_level, domain, constraints)
    
    Returns:
        Customized system prompt
    """
    base_prompt = "You are a helpful AI assistant."
    
    if task_type == "analysis":
        return f"""{base_prompt}

Your task is to provide detailed analysis with:
- Clear structure and organization
- Data-driven insights
- Multiple perspectives
- Actionable recommendations

User expertise level: {context.get('user_level', 'intermediate')}
Domain: {context.get('domain', 'general')}"""

    elif task_type == "creative":
        return f"""{base_prompt}

Your task is to be creative and innovative:
- Think outside the box
- Explore multiple possibilities
- Be imaginative and original
- Provide diverse options

Style preference: {context.get('style', 'balanced')}
Tone: {context.get('tone', 'friendly')}"""

    elif task_type == "technical":
        return f"""{base_prompt}

Your task is to provide technical guidance:
- Be precise and accurate
- Include code examples when relevant
- Explain technical concepts clearly
- Follow best practices

Technology stack: {context.get('tech_stack', 'general')}
Experience level: {context.get('user_level', 'intermediate')}"""

    elif task_type == "support":
        return f"""{base_prompt}

Your task is to provide customer support:
- Be empathetic and patient
- Provide step-by-step guidance
- Offer multiple solutions
- Follow up on concerns

Product: {context.get('product', 'general')}
Issue priority: {context.get('priority', 'normal')}"""

    else:
        return base_prompt
```

### Usage Example

```python
# Analysis task
prompt1 = generate_dynamic_prompt(
    task_type="analysis",
    context={
        "user_level": "expert",
        "domain": "finance"
    }
)

# Creative task
prompt2 = generate_dynamic_prompt(
    task_type="creative",
    context={
        "style": "bold",
        "tone": "enthusiastic"
    }
)

# Technical task
prompt3 = generate_dynamic_prompt(
    task_type="technical",
    context={
        "tech_stack": "Python/Django",
        "user_level": "beginner"
    }
)
```

### Template System

```python
from string import Template

# Define prompt templates
TEMPLATES = {
    "analysis": Template("""You are an expert analyst specializing in $domain.

Analyze the following with:
- $detail_level detail
- Focus on $focus_areas
- Consider $constraints

Provide insights that are $output_style."""),

    "creative": Template("""You are a creative $role.

Generate ideas that are:
- $creativity_level creative
- Aligned with $brand_voice
- Suitable for $audience

Output format: $format""")
}

# Use templates
def generate_from_template(template_name: str, **kwargs):
    template = TEMPLATES[template_name]
    return template.substitute(**kwargs)

# Example
prompt = generate_from_template(
    "analysis",
    domain="marketing",
    detail_level="high",
    focus_areas="ROI and customer engagement",
    constraints="budget limitations",
    output_style="actionable and data-driven"
)
```

### Benefits

- âœ… **Context-aware** - Prompts adapt to task requirements
- âœ… **Consistent quality** - Standardized prompt structure
- âœ… **Easy maintenance** - Centralized prompt management
- âœ… **A/B testing** - Easy to test different prompt variations

**Official Docs:** https://docs.langchain.com/oss/python/langchain/prompts

---

## 3. Complex Structured Output

Handle complex data structures with nested Pydantic models.

### Concept

Real-world applications need complex schemas:
- **Nested objects** - Objects within objects
- **Lists of objects** - Multiple items of same type
- **Validation** - Type checking and constraints
- **Optional fields** - Flexible schemas

### Implementation

```python
from pydantic import BaseModel, Field, validator
from typing import List, Optional, Literal
from datetime import datetime

class Address(BaseModel):
    """Address information."""
    street: str = Field(description="Street address")
    city: str = Field(description="City name")
    country: str = Field(description="Country name")
    postal_code: Optional[str] = Field(None, description="Postal code")

class ContactInfo(BaseModel):
    """Contact information."""
    email: str = Field(description="Email address")
    phone: Optional[str] = Field(None, description="Phone number")
    
    @validator('email')
    def validate_email(cls, v):
        if '@' not in v:
            raise ValueError('Invalid email address')
        return v

class Person(BaseModel):
    """Person information with nested structures."""
    name: str = Field(description="Full name")
    age: int = Field(description="Age in years", ge=0, le=150)
    occupation: str = Field(description="Job title or occupation")
    address: Address = Field(description="Residential address")
    contact: ContactInfo = Field(description="Contact information")
    skills: List[str] = Field(description="List of skills")
    experience_years: int = Field(description="Years of experience", ge=0)
    employment_status: Literal["employed", "unemployed", "self-employed"] = Field(
        description="Current employment status"
    )
    
    @validator('skills')
    def validate_skills(cls, v):
        if len(v) == 0:
            raise ValueError('At least one skill is required')
        return v

class Team(BaseModel):
    """Team with multiple members."""
    team_name: str = Field(description="Name of the team")
    department: str = Field(description="Department name")
    members: List[Person] = Field(description="List of team members")
    created_date: str = Field(description="Team creation date (YYYY-MM-DD)")
    
    @validator('members')
    def validate_members(cls, v):
        if len(v) < 2:
            raise ValueError('Team must have at least 2 members')
        return v
```

### Usage Example

```python
# Request complex structured output
query = """Create a software development team with 2 members.

Respond in this exact JSON format:
{
    "team_name": "team name",
    "department": "department name",
    "members": [
        {
            "name": "full name",
            "age": age_number,
            "occupation": "job title",
            "address": {
                "street": "street address",
                "city": "city name",
                "country": "country name",
                "postal_code": "postal code or null"
            },
            "contact": {
                "email": "email@example.com",
                "phone": "phone number or null"
            },
            "skills": ["skill1", "skill2"],
            "experience_years": years_number,
            "employment_status": "employed/unemployed/self-employed"
        }
    ],
    "created_date": "YYYY-MM-DD"
}"""

result = model.invoke([
    SystemMessage(content="You provide structured JSON responses."),
    HumanMessage(content=query)
])

# Parse and validate
import json
parsed_data = json.loads(result.content)
team = Team(**parsed_data)

# Access nested data
print(f"Team: {team.team_name}")
print(f"Members: {len(team.members)}")
for member in team.members:
    print(f"  - {member.name} ({member.occupation})")
    print(f"    Email: {member.contact.email}")
    print(f"    City: {member.address.city}")
    print(f"    Skills: {', '.join(member.skills)}")
```

### Advanced Validation

```python
from pydantic import BaseModel, Field, validator, root_validator

class AdvancedSchema(BaseModel):
    """Schema with advanced validation."""
    
    # Field-level validation
    price: float = Field(description="Price", gt=0)
    discount: float = Field(description="Discount percentage", ge=0, le=100)
    
    @validator('price')
    def validate_price(cls, v):
        if v > 10000:
            raise ValueError('Price too high')
        return v
    
    # Cross-field validation
    @root_validator
    def validate_discount(cls, values):
        price = values.get('price')
        discount = values.get('discount')
        if discount and price:
            final_price = price * (1 - discount / 100)
            if final_price < 0:
                raise ValueError('Final price cannot be negative')
        return values
    
    # Custom transformation
    @validator('discount', pre=True)
    def convert_discount(cls, v):
        if isinstance(v, str) and v.endswith('%'):
            return float(v.rstrip('%'))
        return v
```

### Benefits

- âœ… **Type safety** - Automatic type checking
- âœ… **Validation** - Built-in data validation
- âœ… **Documentation** - Self-documenting schemas
- âœ… **IDE support** - Autocomplete and type hints

**Official Docs:** https://docs.langchain.com/oss/python/langchain/structured-output

---

## 4. Production Best Practices

### Error Handling

```python
from typing import Optional
import logging

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

def safe_agent_invoke(agent, message: str, config: dict, max_retries: int = 3) -> Optional[str]:
    """
    Safely invoke agent with error handling and retries.
    
    Args:
        agent: The agent to invoke
        message: User message
        config: Configuration with thread_id
        max_retries: Maximum number of retry attempts
    
    Returns:
        Agent response or None if all retries fail
    """
    for attempt in range(max_retries):
        try:
            result = agent.invoke(
                {"messages": [HumanMessage(content=message)]},
                config=config
            )
            return result["messages"][-1].content
            
        except Exception as e:
            logger.error(f"Attempt {attempt + 1} failed: {str(e)}")
            
            if attempt < max_retries - 1:
                wait_time = 2 ** attempt  # Exponential backoff
                logger.info(f"Retrying in {wait_time} seconds...")
                time.sleep(wait_time)
            else:
                logger.error("All retry attempts failed")
                return None

# Usage
response = safe_agent_invoke(
    agent=agent,
    message="What is 2 + 2?",
    config={"configurable": {"thread_id": "1"}},
    max_retries=3
)

if response:
    print(f"Success: {response}")
else:
    print("Failed to get response")
```

### Retry Logic with Exponential Backoff

```python
import time
from functools import wraps

def retry_with_backoff(max_retries=3, base_delay=1):
    """
    Decorator for retry logic with exponential backoff.
    
    Args:
        max_retries: Maximum number of retry attempts
        base_delay: Base delay in seconds (doubles each retry)
    """
    def decorator(func):
        @wraps(func)
        def wrapper(*args, **kwargs):
            for attempt in range(max_retries):
                try:
                    return func(*args, **kwargs)
                except Exception as e:
                    if attempt < max_retries - 1:
                        delay = base_delay * (2 ** attempt)
                        logger.warning(f"Attempt {attempt + 1} failed: {e}. Retrying in {delay}s...")
                        time.sleep(delay)
                    else:
                        logger.error(f"All {max_retries} attempts failed")
                        raise
        return wrapper
    return decorator

# Usage
@retry_with_backoff(max_retries=3, base_delay=1)
def call_agent(agent, message, config):
    return agent.invoke({"messages": [HumanMessage(content=message)]}, config)
```

### Logging and Monitoring

```python
import logging
from datetime import datetime

class AgentLogger:
    """Logger for agent interactions."""
    
    def __init__(self, log_file: str = "agent.log"):
        self.logger = logging.getLogger("AgentLogger")
        self.logger.setLevel(logging.INFO)
        
        # File handler
        fh = logging.FileHandler(log_file)
        fh.setLevel(logging.INFO)
        
        # Console handler
        ch = logging.StreamHandler()
        ch.setLevel(logging.INFO)
        
        # Formatter
        formatter = logging.Formatter(
            '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
        )
        fh.setFormatter(formatter)
        ch.setFormatter(formatter)
        
        self.logger.addHandler(fh)
        self.logger.addHandler(ch)
    
    def log_request(self, user_id: str, message: str):
        """Log user request."""
        self.logger.info(f"[REQUEST] User: {user_id} | Message: {message}")
    
    def log_response(self, user_id: str, response: str, duration: float):
        """Log agent response."""
        self.logger.info(
            f"[RESPONSE] User: {user_id} | Duration: {duration:.2f}s | Response: {response[:100]}..."
        )
    
    def log_error(self, user_id: str, error: str):
        """Log error."""
        self.logger.error(f"[ERROR] User: {user_id} | Error: {error}")

# Usage
logger = AgentLogger()

start_time = time.time()
logger.log_request(user_id="user-123", message="What is 2 + 2?")

try:
    response = agent.invoke(...)
    duration = time.time() - start_time
    logger.log_response(
        user_id="user-123",
        response=response["messages"][-1].content,
        duration=duration
    )
except Exception as e:
    logger.log_error(user_id="user-123", error=str(e))
```

### Performance Optimization

```python
import asyncio
from typing import List

async def batch_process_messages(agent, messages: List[str], config: dict):
    """
    Process multiple messages concurrently.
    
    Args:
        agent: The agent to use
        messages: List of messages to process
        config: Configuration with thread_id
    
    Returns:
        List of responses
    """
    async def process_single(message: str):
        return agent.invoke(
            {"messages": [HumanMessage(content=message)]},
            config=config
        )
    
    # Process all messages concurrently
    tasks = [process_single(msg) for msg in messages]
    results = await asyncio.gather(*tasks, return_exceptions=True)
    
    # Extract responses
    responses = []
    for result in results:
        if isinstance(result, Exception):
            responses.append(f"Error: {str(result)}")
        else:
            responses.append(result["messages"][-1].content)
    
    return responses

# Usage
messages = [
    "What is 2 + 2?",
    "What is 3 + 3?",
    "What is 4 + 4?"
]

responses = asyncio.run(batch_process_messages(agent, messages, config))
for msg, resp in zip(messages, responses):
    print(f"Q: {msg}\nA: {resp}\n")
```

### Rate Limiting

```python
import time
from collections import deque

class RateLimiter:
    """Rate limiter for API calls."""
    
    def __init__(self, max_calls: int, time_window: int):
        """
        Initialize rate limiter.
        
        Args:
            max_calls: Maximum number of calls allowed
            time_window: Time window in seconds
        """
        self.max_calls = max_calls
        self.time_window = time_window
        self.calls = deque()
    
    def allow_request(self) -> bool:
        """Check if request is allowed."""
        now = time.time()
        
        # Remove old calls outside time window
        while self.calls and self.calls[0] < now - self.time_window:
            self.calls.popleft()
        
        # Check if under limit
        if len(self.calls) < self.max_calls:
            self.calls.append(now)
            return True
        
        return False
    
    def wait_if_needed(self):
        """Wait if rate limit is exceeded."""
        while not self.allow_request():
            time.sleep(0.1)

# Usage
rate_limiter = RateLimiter(max_calls=10, time_window=60)  # 10 calls per minute

for i in range(20):
    rate_limiter.wait_if_needed()
    response = agent.invoke(...)
    print(f"Request {i + 1} completed")
```

---

## Key Takeaways

1. **Dynamic Model Selection** - Choose models based on task complexity
2. **Dynamic Prompts** - Generate context-aware prompts
3. **Complex Schemas** - Handle nested data structures with Pydantic
4. **Error Handling** - Implement retry logic and graceful failures
5. **Logging** - Monitor agent interactions and performance
6. **Rate Limiting** - Prevent API overuse
7. **Async Processing** - Handle multiple requests concurrently

---

## Next Steps

After mastering these patterns:

1. **Implement in Production** - Apply patterns to real applications
2. **Monitor Performance** - Track metrics and optimize
3. **A/B Testing** - Test different models and prompts
4. **Scale Up** - Handle high-volume requests
5. **Custom Patterns** - Develop your own advanced patterns

---

## Official Documentation

- **LangChain Models**: https://docs.langchain.com/oss/python/langchain/models
- **LangChain Prompts**: https://docs.langchain.com/oss/python/langchain/prompts
- **Structured Output**: https://docs.langchain.com/oss/python/langchain/structured-output
- **Pydantic**: https://docs.pydantic.dev/

---

**Ready for Production! ðŸš€**
