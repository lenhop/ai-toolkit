# Simple AI Agent Basics - Complete Guide

## Overview

This guide explains `2.simple_agent_basics.py` - a comprehensive introduction to building AI agents with LangChain following **official documentation patterns**.

**What you'll learn:** Models, Messages, Tools, Memory, Agents, Structured Output, and when to use agents vs models.

## Quick Start

```bash
# Run the example
python examples/2.simple_agent_basics.py
```

**Prerequisites:**
- Python 3.11+
- AI Toolkit installed: `pip install -e .`
- DeepSeek API key in `.env`
- Dependencies: `pip install -r requirements.txt`

---

## 1. Models - The Reasoning Engine

Models are the brain of your agent, driving decision-making and response generation.

### Code Example
```python
from ai_toolkit.models.model_manager import ModelManager

model_manager = ModelManager()
model = model_manager.create_model(
    provider_name="deepseek",     # deepseek, qwen, glm
    model_name="deepseek-chat",
    temperature=0.7,              # 0.0-2.0 (lower = more deterministic)
    max_tokens=2000               # Maximum response length
)
```

### Key Parameters
- **temperature**: Controls randomness
  - `0.0` - Deterministic, consistent
  - `0.7` - Balanced creativity (recommended)
  - `2.0` - Very creative, unpredictable
- **max_tokens**: Maximum response length (500-4000+)

**Official Docs:** https://docs.langchain.com/oss/python/langchain/models

---

## 2. Messages - Conversation Building Blocks

Messages are the fundamental unit of context. Three types: SystemMessage, HumanMessage, AIMessage.

### Message Types

#### SystemMessage - Define Agent Behavior
```python
from langchain_core.messages import SystemMessage

system_msg = SystemMessage(content="You are a helpful AI assistant with access to tools.")
```
- **Purpose:** Set agent personality and capabilities
- **When:** At the start of conversation
- **Analogy:** Instructions to a new employee

#### HumanMessage - User Input
```python
from langchain_core.messages import HumanMessage

human_msg = HumanMessage(content="What is 2 + 2?")
```
- **Purpose:** Represent user questions/requests
- **When:** Every user message
- **Analogy:** Speaking in a conversation

#### AIMessage - Agent Response
```python
from langchain_core.messages import AIMessage

ai_msg = AIMessage(content="2 + 2 equals 4.")
```
- **Purpose:** Represent agent responses
- **When:** Automatically created by agent
- **Note:** Don't create these manually

### Message Flow
```
SystemMessage: "You are a helpful assistant"
     â†“
HumanMessage: "What is 2 + 2?"
     â†“
AIMessage: "2 + 2 equals 4"
     â†“
HumanMessage: "What about 3 + 3?"
     â†“
AIMessage: "3 + 3 equals 6"
```

### Conversation Structure
```python
messages = [
    SystemMessage(content="You are a helpful assistant"),
    HumanMessage(content="Hello!"),
    AIMessage(content="Hi! How can I help?"),
    HumanMessage(content="What is 5 + 5?")
]
```

**Official Docs:** https://docs.langchain.com/oss/python/langchain/messages

---

## 3. Tools - Extending Agent Capabilities

Tools allow agents to fetch data, execute code, call APIs, and more.

### Defining Tools
```python
from langchain_core.tools import tool

@tool
def calculator(expression: str) -> str:
    """
    Calculate mathematical expressions.
    
    Use this tool when you need to perform mathematical calculations.
    Supports basic arithmetic operations: +, -, *, /, **, %.
    
    Args:
        expression: A mathematical expression to evaluate
    
    Returns:
        The result of the calculation as a string
    """
    try:
        result = eval(expression, {"__builtins__": {}}, {})
        return f"Result: {result}"
    except Exception as e:
        return f"Error: {str(e)}"

@tool
def get_weather(city: str) -> str:
    """
    Get current weather information for a city.
    
    Use this tool when the user asks about weather conditions.
    
    Args:
        city: Name of the city
    
    Returns:
        Weather information including temperature and conditions
    """
    weather_data = {
        "beijing": "Sunny, 22Â°C, Light breeze",
        "tokyo": "Clear, 15Â°C, Pleasant",
    }
    return f"Weather in {city}: {weather_data.get(city.lower(), 'Data not available')}"

tools = [calculator, get_weather]
```

### Best Practices
- âœ… Write clear, descriptive docstrings (model reads these!)
- âœ… Use type hints (REQUIRED)
- âœ… Return strings the model can interpret
- âœ… Handle errors gracefully

**Official Docs:** https://docs.langchain.com/oss/python/langchain/tools

---

## 4. Memory - Conversation History

Memory allows agents to remember previous conversations.

### Creating Memory
```python
from langgraph.checkpoint.memory import MemorySaver

# In-memory storage (lost on restart)
checkpointer = MemorySaver()

# Configuration with thread_id
config = {"configurable": {"thread_id": "conversation-1"}}
```

### Memory Types
- **MemorySaver**: In-memory (session-based)
- **SqliteSaver**: Persistent to disk
- **RedisSaver**: Distributed memory for scaling

### Thread ID Isolation
```python
# Same thread_id = shared memory (agent remembers)
config1 = {"configurable": {"thread_id": "user-1"}}
agent.invoke({"messages": [HumanMessage("I like pizza")]}, config1)
agent.invoke({"messages": [HumanMessage("What do I like?")]}, config1)
# Agent remembers: "You like pizza"

# Different thread_id = separate conversations
config2 = {"configurable": {"thread_id": "user-2"}}
agent.invoke({"messages": [HumanMessage("What do I like?")]}, config2)
# Agent doesn't know (different conversation)
```

**Official Docs:** https://docs.langchain.com/oss/python/langchain/short-term-memory

---

## 5. Agents - Combining Everything

Agents combine models with tools using the **ReAct pattern** (Reason + Act).

### ReAct Pattern Flow
```
User Question
     â†“
Agent Receives Question
     â†“
Agent Reasons: "Do I need a tool?"
     â†“
   Yes â†’ Call Tool â†’ Observe Result â†’ Reason Again
     â†“
   No â†’ Formulate Answer
     â†“
Return Response
```

### Creating an Agent
```python
from langchain.agents import create_agent

system_prompt = """You are a helpful AI assistant with access to tools.

Your capabilities:
- Perform mathematical calculations using the calculator tool
- Provide weather information using the get_weather tool

Guidelines:
- Be friendly and helpful
- Use tools when needed for accurate information
- Explain your reasoning clearly"""

agent = create_agent(
    model=model,                    # The LLM for reasoning
    tools=tools,                    # List of available tools
    checkpointer=checkpointer,      # Memory for conversation history
    system_prompt=system_prompt     # Instructions for agent behavior
)
```

### Running the Agent
```python
result = agent.invoke(
    {"messages": [HumanMessage(content="What is 123 * 456?")]},
    config=config  # Include thread_id for memory
)

# Extract final response
final_response = result["messages"][-1].content
print(final_response)
```

### Example Interactions

**Example 1: Mathematical Calculation**
```
User: "What is 123 multiplied by 456?"
Agent: Uses calculator tool â†’ Returns "56,088"
```

**Example 2: Weather Query**
```
User: "What's the weather like in Tokyo?"
Agent: Uses get_weather tool â†’ Returns "Clear, 15Â°C, Pleasant"
```

**Example 3: Memory Test**
```
User: "If the temperature in Tokyo increases by 5 degrees, what would it be?"
Agent: Remembers Tokyo's temperature (15Â°C) â†’ Uses calculator â†’ Returns "20Â°C"
```

**Official Docs:** https://docs.langchain.com/oss/python/langchain/agents

---

## 6. Structured Output - Formatted Responses

Get predictable, parseable responses using Pydantic schemas.

### Defining a Schema
```python
from pydantic import BaseModel, Field
from typing import Literal

class WeatherInfo(BaseModel):
    """Structured weather information."""
    city: str = Field(description="The city name")
    temperature: int = Field(description="Temperature in Celsius")
    condition: str = Field(description="Weather condition")
    confidence: Literal["high", "medium", "low"] = Field(
        description="Confidence level of the information"
    )
```

### Requesting Structured Output
```python
query = """What's the weather in Beijing? 
Respond in this exact JSON format:
{
    "city": "city name",
    "temperature": temperature_in_celsius,
    "condition": "weather condition",
    "confidence": "high/medium/low"
}"""

result = model.invoke([
    SystemMessage(content="You provide structured JSON responses."),
    HumanMessage(content=query)
])

# Parse and validate
import json
parsed_data = json.loads(result.content)
weather_info = WeatherInfo(**parsed_data)
```

**Use Cases:** API integrations, database operations, data extraction

**Official Docs:** https://docs.langchain.com/oss/python/langchain/structured-output

---

## Agent vs Model - When to Use What

### ðŸ¤– AGENT
**What it includes:**
- âœ… Model (LLM)
- âœ… Tools (calculator, weather, etc.)
- âœ… Memory (conversation history)
- âœ… ReAct logic (Reason â†’ Act â†’ Observe)

**Best for:**
- Complex workflows
- Multi-step tasks
- Tool usage required
- Conversation context needed

**Example:**
```python
agent = create_agent(model=model, tools=tools, checkpointer=checkpointer)
result = agent.invoke({"messages": [HumanMessage("What's the weather in Beijing?")]}, config)
# Agent uses get_weather tool
```

### ðŸ’¬ MODEL
**What it includes:**
- âœ… Model (LLM)
- âŒ No tools
- âŒ No memory
- âŒ No ReAct logic

**Best for:**
- Simple question-answer
- Structured/formatted output
- No tools needed
- No memory needed

**Example:**
```python
result = model.invoke([
    SystemMessage(content="You are helpful"),
    HumanMessage(content="What is 2 + 2?")
])
# Model just answers directly
```

### Decision Guide

**Use AGENT when:**
- âœ… Need to call external APIs, databases, calculators
- âœ… Need to remember previous conversation
- âœ… Need multi-step reasoning

**Use MODEL when:**
- âœ… Simple question-answer
- âœ… Structured output (JSON, XML)
- âœ… Each query is independent

---

## Common Patterns

### Pattern 1: Simple Question-Answer
```python
# No tools needed, just model
result = model.invoke([
    SystemMessage(content="You are a helpful assistant"),
    HumanMessage(content="What is Python?")
])
```

### Pattern 2: Agent with Tools
```python
# Agent decides when to use tools
result = agent.invoke(
    {"messages": [HumanMessage(content="Calculate 123 * 456")]},
    config={"configurable": {"thread_id": "1"}}
)
```

### Pattern 3: Multi-turn Conversation
```python
config = {"configurable": {"thread_id": "user-1"}}

# First message
result1 = agent.invoke(
    {"messages": [HumanMessage(content="What's the weather in Tokyo?")]},
    config=config
)

# Second message - agent remembers first
result2 = agent.invoke(
    {"messages": [HumanMessage(content="What if it's 5 degrees warmer?")]},
    config=config  # Same thread_id = shared memory
)
```

### Pattern 4: Separate Conversations
```python
# User 1
config_user1 = {"configurable": {"thread_id": "user-1"}}
result1 = agent.invoke({"messages": [HumanMessage(content="Hello")]}, config_user1)

# User 2 - separate memory
config_user2 = {"configurable": {"thread_id": "user-2"}}
result2 = agent.invoke({"messages": [HumanMessage(content="Hello")]}, config_user2)
```

---

## Troubleshooting

### Agent not using tools?
**Solution:**
- Check tool docstrings are clear and descriptive
- Mention tools in system prompt
- Verify tools are passed to `create_agent()`

### Memory not working?
**Solution:**
- Use same `thread_id` across invocations
- Pass `config` to `agent.invoke()`
- Provide checkpointer to `create_agent()`

### Structured output parsing fails?
**Solution:**
- Check JSON format in model response
- Handle markdown code blocks (```json)
- Validate against Pydantic schema

### Import errors?
**Solution:**
```python
# Correct imports
from langchain_core.messages import HumanMessage, SystemMessage, AIMessage
from langchain_core.tools import tool
from langchain.agents import create_agent
from langgraph.checkpoint.memory import MemorySaver
```

---

## Quick Reference

### Quick Start Template
```python
from langchain_core.messages import HumanMessage, SystemMessage
from langchain_core.tools import tool
from langchain.agents import create_agent
from langgraph.checkpoint.memory import MemorySaver
from ai_toolkit.models.model_manager import ModelManager

# 1. Create Model
model_manager = ModelManager()
model = model_manager.create_model(
    provider_name="deepseek",
    model_name="deepseek-chat",
    temperature=0.7,
    max_tokens=2000
)

# 2. Define Tools
@tool
def my_tool(input: str) -> str:
    """Tool description - model reads this to decide when to use it."""
    return f"Result: {input}"

tools = [my_tool]

# 3. Create Memory
checkpointer = MemorySaver()
config = {"configurable": {"thread_id": "conversation-1"}}

# 4. Create Agent
system_prompt = "You are a helpful assistant with access to tools."
agent = create_agent(
    model=model,
    tools=tools,
    checkpointer=checkpointer,
    system_prompt=system_prompt
)

# 5. Run Agent
result = agent.invoke(
    {"messages": [HumanMessage(content="Your question here")]},
    config=config
)
print(result["messages"][-1].content)
```

---

## Key Takeaways

1. **Models** provide the reasoning capability
2. **Messages** structure conversations (System, Human, AI)
3. **Tools** extend agent capabilities beyond text generation
4. **Memory** enables context retention across interactions
5. **Agents** combine models + tools + memory using ReAct pattern
6. **Structured Output** ensures predictable, parseable responses
7. **thread_id** isolates different conversations
8. **Use Agent** for complex workflows, **Use Model** for simple queries

---

## Next Steps

After mastering this example:

1. **Add Custom Tools** - Create your own tools for specific tasks
2. **Experiment with Prompts** - Try different system prompts
3. **Test Memory** - Use different thread_ids for conversation isolation
4. **Define Schemas** - Create your own Pydantic schemas
5. **Advanced Patterns** - Explore `3.advanced_agent_patterns.py`

---

## Official Documentation

- **Models**: https://docs.langchain.com/oss/python/langchain/models
- **Messages**: https://docs.langchain.com/oss/python/langchain/messages
- **Tools**: https://docs.langchain.com/oss/python/langchain/tools
- **Memory**: https://docs.langchain.com/oss/python/langchain/short-term-memory
- **Agents**: https://docs.langchain.com/oss/python/langchain/agents
- **Structured Output**: https://docs.langchain.com/oss/python/langchain/structured-output

---

**Happy Learning! ðŸŽ“**
